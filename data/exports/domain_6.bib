% Domain 6: Generative Interactive Worlds
% Citation counts from Semantic Scholar/Web Search, December 2025
% NOTE: Some counts estimated. Verify with Google Scholar when rate limit resets

% === TIER 1: Foundational (>1,000 citations) ===

@inproceedings{ha2018world,
  title={World Models},
  author={Ha, David and Schmidhuber, J{\"u}rgen},
  booktitle={Advances in Neural Information Processing Systems},
  volume={31},
  pages={2451--2463},
  year={2018},
  organization={NeurIPS},
  url={https://arxiv.org/abs/1803.10122},
  note={1,290 citations - Foundational world model paper, dream training}
}

@inproceedings{oord2017neural,
  title={Neural Discrete Representation Learning},
  author={van den Oord, A{\"a}ron and Vinyals, Oriol and Kavukcuoglu, Koray},
  booktitle={Advances in Neural Information Processing Systems},
  volume={30},
  pages={6306--6315},
  year={2017},
  organization={NeurIPS},
  url={https://arxiv.org/abs/1711.00937},
  note={~1,963 citations - VQ-VAE: Foundation for discrete neural representations}
}

% === TIER 2: Major Recent (100-1,000 citations) ===

@article{hafner2023dreamerv3,
  title={Mastering Diverse Domains through World Models},
  author={Hafner, Danijar and Pasukonis, Jurgis and Ba, Jimmy and Lillicrap, Timothy},
  journal={arXiv preprint arXiv:2301.04104},
  year={2023},
  url={https://arxiv.org/abs/2301.04104},
  note={792 citations - DreamerV3: State-of-the-art world model, published in Nature 2025}
}

@inproceedings{bruce2024genie,
  title={Genie: Generative Interactive Environments},
  author={Bruce, Jake and Dennis, Michael and Edwards, Ashley and Parker-Holder, Jack and Shi, Yuge and Hughes, Edward and Lai, Matthew and Mavalankar, Aditi and Steigerwald, Richie and Apps, Chris and others},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2024},
  url={https://arxiv.org/abs/2402.15391},
  note={~341 citations - First 11B foundation world model, generates playable worlds from images}
}

@article{valevski2024gamengen,
  title={Diffusion Models Are Real-Time Game Engines},
  author={Valevski, Dani and Leviathan, Yaniv and Arar, Moab and Fruchter, Shlomi},
  journal={arXiv preprint arXiv:2408.14837},
  year={2024},
  url={https://arxiv.org/abs/2408.14837},
  note={~152 citations - GameNGen: DOOM running on neural network at 20 FPS}
}

@inproceedings{kim2020gamegan,
  title={Learning to Simulate Dynamic Environments with {GameGAN}},
  author={Kim, Seung Wook and Zhou, Yuhao and Philion, Jonah and Torralba, Antonio and Fidler, Sanja},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={1231--1240},
  year={2020},
  url={https://arxiv.org/abs/2005.12126},
  note={~400 citations - GAN-based game simulation, Pac-Man recreation}
}

@inproceedings{micheli2023iris,
  title={Transformers are Sample-Efficient World Models},
  author={Micheli, Vincent and Alonso, Eloi and Fleuret, Fran{\c{c}}ois},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2023},
  url={https://arxiv.org/abs/2209.00588},
  note={~117 citations - IRIS: Notable Top 5\%, VQ-VAE + Transformer world model}
}

% === TIER 3: Frontier Work (justified) ===

@misc{decart2024oasis,
  title={Oasis: Real-Time {AI} Game Generation},
  author={{Decart} and {Etched}},
  year={2024},
  url={https://oasis-model.github.io/},
  note={Technical report - Real-time Minecraft generation at 20 FPS, DiT architecture}
}

@misc{openai2024sora,
  title={Video Generation Models as World Simulators},
  author={{OpenAI}},
  year={2024},
  url={https://openai.com/index/video-generation-models-as-world-simulators/},
  note={Technical report - Sora: Frames video generation as world simulation}
}

% === RELATED/SUPPORTING ===

@inproceedings{walker2021vqvae,
  title={Predicting Video with {VQVAE}},
  author={Walker, Jacob and Razavi, Ali and van den Oord, A{\"a}ron},
  booktitle={arXiv preprint arXiv:2103.01950},
  year={2021},
  url={https://arxiv.org/abs/2103.01950},
  note={VQ-VAE for video prediction, hierarchical latent variables}
}
